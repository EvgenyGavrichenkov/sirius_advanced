<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>2 Неделя 2, День 1 | Анализ данных в социальных науках с помощью языка R. Вторая неделя</title>
  <meta name="description" content="Конспекты для ‘Анализ данных в социальных науках с помощью языка R’ в Сириусе">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="2 Неделя 2, День 1 | Анализ данных в социальных науках с помощью языка R. Вторая неделя" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Конспекты для ‘Анализ данных в социальных науках с помощью языка R’ в Сириусе" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Неделя 2, День 1 | Анализ данных в социальных науках с помощью языка R. Вторая неделя" />
  
  <meta name="twitter:description" content="Конспекты для ‘Анализ данных в социальных науках с помощью языка R’ в Сириусе" />
  

<meta name="author" content="Иван Поздняков">


<meta name="date" content="2020-01-30">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="d2.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.6/datatables.js"></script>
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<script src="libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.46.1/plotly-latest.min.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>
<script src="libs/d3-4.5.0/d3.min.js"></script>
<script src="libs/forceNetwork-binding-0.4/forceNetwork.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Анализ данных в социальных науках с помощью языка R. Вторая неделя </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Начало работы</a></li>
<li class="chapter" data-level="2" data-path="d1.html"><a href="d1.html"><i class="fa fa-check"></i><b>2</b> Неделя 2, День 1</a><ul>
<li class="chapter" data-level="2.1" data-path="d1.html"><a href="d1.html#warm"><i class="fa fa-check"></i><b>2.1</b> Warmup exercise</a></li>
<li class="chapter" data-level="2.2" data-path="d1.html"><a href="d1.html#lm"><i class="fa fa-check"></i><b>2.2</b> Простая линейная регрессия</a><ul>
<li class="chapter" data-level="2.2.1" data-path="d1.html"><a href="d1.html#lm"><i class="fa fa-check"></i><b>2.2.1</b> Функция lm()</a></li>
<li class="chapter" data-level="2.2.2" data-path="d1.html"><a href="d1.html#interpret"><i class="fa fa-check"></i><b>2.2.2</b> Интерпретация вывода линейной регрессии</a></li>
<li class="chapter" data-level="2.2.3" data-path="d1.html"><a href="d1.html#lm_a"><i class="fa fa-check"></i><b>2.2.3</b> Допущения линейной регрессии</a></li>
<li class="chapter" data-level="2.2.4" data-path="d1.html"><a href="d1.html#outliers"><i class="fa fa-check"></i><b>2.2.4</b> Влияние выбросов на линейную модель</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="d1.html"><a href="d1.html#lm_mult"><i class="fa fa-check"></i><b>2.3</b> Множественная линейная регрессия</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="d2.html"><a href="d2.html"><i class="fa fa-check"></i><b>3</b> Неделя 2, День 2</a><ul>
<li class="chapter" data-level="3.1" data-path="d2.html"><a href="d2.html#anova"><i class="fa fa-check"></i><b>3.1</b> Дисперсионный анализ (ANOVA)</a><ul>
<li class="chapter" data-level="3.1.1" data-path="d2.html"><a href="d2.html#aov"><i class="fa fa-check"></i><b>3.1.1</b> Функция aov()</a></li>
<li class="chapter" data-level="3.1.2" data-path="d2.html"><a href="d2.html#anova_nhst"><i class="fa fa-check"></i><b>3.1.2</b> Тестирование значимости нулевой гипотезы в ANOVA.</a></li>
<li class="chapter" data-level="3.1.3" data-path="d2.html"><a href="d2.html#anova_posthoc"><i class="fa fa-check"></i><b>3.1.3</b> Post-hoc тесты</a></li>
<li class="chapter" data-level="3.1.4" data-path="d2.html"><a href="d2.html#aov_as_lm"><i class="fa fa-check"></i><b>3.1.4</b> ANOVA и т-тест как частные случаи линейной регрессии</a></li>
<li class="chapter" data-level="3.1.5" data-path="d2.html"><a href="d2.html#dummy"><i class="fa fa-check"></i><b>3.1.5</b> Dummy coding</a></li>
<li class="chapter" data-level="3.1.6" data-path="d2.html"><a href="d2.html#aova"><i class="fa fa-check"></i><b>3.1.6</b> Допущения ANOVA</a></li>
<li class="chapter" data-level="3.1.7" data-path="d2.html"><a href="d2.html#fact_aov"><i class="fa fa-check"></i><b>3.1.7</b> Многофакторный дисперсионный анализ (Factorial ANOVA)</a></li>
<li class="chapter" data-level="3.1.8" data-path="d2.html"><a href="d2.html#rm_aov"><i class="fa fa-check"></i><b>3.1.8</b> Дисперсионный анализ с повторными измерениями (Repeated-measures ANOVA)</a></li>
<li class="chapter" data-level="3.1.9" data-path="d2.html"><a href="d2.html#mixed_aov"><i class="fa fa-check"></i><b>3.1.9</b> Смешанный дисперсионный анализ (Mixed between-within subjects ANOVA)</a></li>
<li class="chapter" data-level="3.1.10" data-path="d2.html"><a href="d2.html#aov_sum"><i class="fa fa-check"></i><b>3.1.10</b> Заключение</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="d2.html"><a href="d2.html#rmd"><i class="fa fa-check"></i><b>3.2</b> RMarkdown</a><ul>
<li class="chapter" data-level="3.2.1" data-path="d2.html"><a href="d2.html#chunk"><i class="fa fa-check"></i><b>3.2.1</b> Настройки чанка</a></li>
<li class="chapter" data-level="3.2.2" data-path="d2.html"><a href="d2.html#chunks"><i class="fa fa-check"></i><b>3.2.2</b> Настройка нескольких чанков</a></li>
<li class="chapter" data-level="3.2.3" data-path="d2.html"><a href="d2.html#python"><i class="fa fa-check"></i><b>3.2.3</b> Чанки с Python!</a></li>
<li class="chapter" data-level="3.2.4" data-path="d2.html"><a href="d2.html#inline"><i class="fa fa-check"></i><b>3.2.4</b> Код вне чанков (inline code)</a></li>
<li class="chapter" data-level="3.2.5" data-path="d2.html"><a href="d2.html#md"><i class="fa fa-check"></i><b>3.2.5</b> Синтаксис Markdown (без R)</a></li>
<li class="chapter" data-level="3.2.6" data-path="d2.html"><a href="d2.html#rmd_tables"><i class="fa fa-check"></i><b>3.2.6</b> Таблицы</a></li>
<li class="chapter" data-level="3.2.7" data-path="d2.html"><a href="d2.html#vis"><i class="fa fa-check"></i><b>3.2.7</b> Визуализации</a></li>
<li class="chapter" data-level="3.2.8" data-path="d2.html"><a href="d2.html#din_vis"><i class="fa fa-check"></i><b>3.2.8</b> Динамические визуализации в plotly</a></li>
<li class="chapter" data-level="3.2.9" data-path="d2.html"><a href="d2.html#html"><i class="fa fa-check"></i><b>3.2.9</b> Вставлять HTML</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="d3.html"><a href="d3.html"><i class="fa fa-check"></i><b>4</b> Неделя 2, День 3</a><ul>
<li class="chapter" data-level="4.1" data-path="d3.html"><a href="d3.html#text"><i class="fa fa-check"></i><b>4.1</b> Введение в работу с текстом</a></li>
<li class="chapter" data-level="4.2" data-path="d3.html"><a href="d3.html#text_base"><i class="fa fa-check"></i><b>4.2</b> Базовые операции с текстом</a><ul>
<li class="chapter" data-level="4.2.1" data-path="d3.html"><a href="d3.html#text_c"><i class="fa fa-check"></i><b>4.2.1</b> Объединение и разъединение строк</a></li>
<li class="chapter" data-level="4.2.2" data-path="d3.html"><a href="d3.html#text_len"><i class="fa fa-check"></i><b>4.2.2</b> Подсчет длины строк</a></li>
<li class="chapter" data-level="4.2.3" data-path="d3.html"><a href="d3.html#text_cut"><i class="fa fa-check"></i><b>4.2.3</b> Выделение подстрок и обрезание строк</a></li>
<li class="chapter" data-level="4.2.4" data-path="d3.html"><a href="d3.html#text_to"><i class="fa fa-check"></i><b>4.2.4</b> Изменение регистра</a></li>
<li class="chapter" data-level="4.2.5" data-path="d3.html"><a href="d3.html#text_rand"><i class="fa fa-check"></i><b>4.2.5</b> Случайные последовательности</a></li>
<li class="chapter" data-level="4.2.6" data-path="d3.html"><a href="d3.html#text_sort"><i class="fa fa-check"></i><b>4.2.6</b> Сортировка</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="d3.html"><a href="d3.html#regexp"><i class="fa fa-check"></i><b>4.3</b> Поиск паттернов и регулярные выражения</a><ul>
<li class="chapter" data-level="4.3.1" data-path="d3.html"><a href="d3.html#grep"><i class="fa fa-check"></i><b>4.3.1</b> grep(), gsub()</a></li>
<li class="chapter" data-level="4.3.2" data-path="d3.html"><a href="d3.html#reg"><i class="fa fa-check"></i><b>4.3.2</b> Регулярные выражения</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="d3.html"><a href="d3.html#text_next"><i class="fa fa-check"></i><b>4.4</b> Анализ текста - что дальше?</a></li>
<li class="chapter" data-level="4.5" data-path="d3.html"><a href="d3.html#fuzzy"><i class="fa fa-check"></i><b>4.5</b> Fuzzy matching</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="d4.html"><a href="d4.html"><i class="fa fa-check"></i><b>5</b> Неделя 2, День 4</a><ul>
<li class="chapter" data-level="5.1" data-path="d4.html"><a href="d4.html#multi"><i class="fa fa-check"></i><b>5.1</b> Многомерные методы анализа данных</a></li>
<li class="chapter" data-level="5.2" data-path="d4.html"><a href="d4.html#heatmap"><i class="fa fa-check"></i><b>5.2</b> Хитмап корреляций</a></li>
<li class="chapter" data-level="5.3" data-path="d4.html"><a href="d4.html#pca"><i class="fa fa-check"></i><b>5.3</b> Анализ главных компонент (Principal component analysis)</a><ul>
<li class="chapter" data-level="5.3.1" data-path="d4.html"><a href="d4.html#pca_n"><i class="fa fa-check"></i><b>5.3.1</b> Количество извлекаемых компонент</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="d4.html"><a href="d4.html#fa"><i class="fa fa-check"></i><b>5.4</b> Эксплораторный факторный анализ</a></li>
<li class="chapter" data-level="5.5" data-path="d4.html"><a href="d4.html#cfa"><i class="fa fa-check"></i><b>5.5</b> Конфирматорный факторный анализ</a></li>
<li class="chapter" data-level="5.6" data-path="d4.html"><a href="d4.html#other_multi"><i class="fa fa-check"></i><b>5.6</b> Другие многомерные методы</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="d5.html"><a href="d5.html"><i class="fa fa-check"></i><b>6</b> Неделя 2, День 5</a><ul>
<li class="chapter" data-level="6.1" data-path="d5.html"><a href="d5.html#style"><i class="fa fa-check"></i><b>6.1</b> Стиль кода</a></li>
<li class="chapter" data-level="6.2" data-path="d5.html"><a href="d5.html#repr"><i class="fa fa-check"></i><b>6.2</b> Вопроизводимость исследований</a><ul>
<li class="chapter" data-level="6.2.1" data-path="d5.html"><a href="d5.html#quest"><i class="fa fa-check"></i><b>6.2.1</b> Спорные исследовательские практики</a></li>
<li class="chapter" data-level="6.2.2" data-path="d5.html"><a href="d5.html#repr_r"><i class="fa fa-check"></i><b>6.2.2</b> Вопроизводимые исследования в R</a></li>
<li class="chapter" data-level="6.2.3" data-path="d5.html"><a href="d5.html#power"><i class="fa fa-check"></i><b>6.2.3</b> Статистическая мощность</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Анализ данных в социальных науках с помощью языка R. Вторая неделя</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="d1" class="section level1">
<h1><span class="header-section-number">2</span> Неделя 2, День 1</h1>
<div id="warm" class="section level2">
<h2><span class="header-section-number">2.1</span> Warmup exercise</h2>
<p>Итак, давайте загрузим датасет про студентов и вес их рюкзаков и сконвертируем его в data.table:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;Stat2Data&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(Stat2Data)
<span class="kw">library</span>(data.table)</code></pre></div>
<pre><code>## data.table 1.12.8 using 2 threads (see ?getDTthreads).  Latest news: r-datatable.com</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;Backpack&quot;</span>)
back &lt;-<span class="st"> </span><span class="kw">as.data.table</span>(Backpack)</code></pre></div>
<p><strong>Самостоятельное задание:</strong></p>
<ol style="list-style-type: decimal">
<li>Исследуйте колонки BackpackWeight и BodyWeight. В чем измеряются эти переменные? Переведите их в килограммы, создав колонки BackpackWeightKG, BodyWeightKG.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[, <span class="kw">summary</span>(BackpackWeight)]</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    2.00    8.00   11.00   11.66   14.25   35.00</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[, <span class="kw">summary</span>(BodyWeight)]</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   105.0   130.0   147.5   153.1   170.0   270.0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[,BackpackWeightKG<span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="fl">0.45359237</span><span class="op">*</span>BackpackWeight]
back[,BodyWeightKG<span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="fl">0.45359237</span><span class="op">*</span>BodyWeight]</code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Присвойте id каждому испытуемому.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[,id<span class="op">:</span><span class="er">=</span><span class="dv">1</span><span class="op">:</span>.N]</code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Как различается вес рюкзака в зависимости от пола? Кто весит больше? Если допустить, что выборка репрезентативна, то можно ли сделать вывод о различии по среднему весу в генеральной совокупности?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[,<span class="kw">mean</span>(BackpackWeightKG), by =<span class="st"> </span>Sex]</code></pre></div>
<pre><code>##       Sex       V1
## 1: Female 5.006010
## 2:   Male 5.634625</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[,<span class="kw">t.test</span>(BackpackWeightKG <span class="op">~</span><span class="st"> </span>Sex)]</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  BackpackWeightKG by Sex
## t = -1.1782, df = 86.25, p-value = 0.242
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.6892365  0.4320067
## sample estimates:
## mean in group Female   mean in group Male 
##             5.006010             5.634625</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Повторите пункт 3 для веса самих студентов.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[,<span class="kw">mean</span>(BodyWeightKG), by =<span class="st"> </span>Sex]</code></pre></div>
<pre><code>##       Sex       V1
## 1: Female 62.28236
## 2:   Male 78.14893</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[,<span class="kw">t.test</span>(BodyWeightKG <span class="op">~</span><span class="st"> </span>Sex)]</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  BodyWeightKG by Sex
## t = -7.0863, df = 77.002, p-value = 5.704e-10
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -20.32511 -11.40803
## sample estimates:
## mean in group Female   mean in group Male 
##             62.28236             78.14893</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Визуализируйте распределение этих двух переменных в зависимости от пола (используя ggplot2)</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">ggplot</span>(back)<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> BodyWeightKG, <span class="dt">fill =</span> Sex), <span class="dt">bins =</span> <span class="dv">15</span>, <span class="dt">position =</span> <span class="st">&quot;identity&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.7</span>)</code></pre></div>
<p><img src="sirius_advanced_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(back)<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> BackpackWeightKG, <span class="dt">fill =</span> Sex), <span class="dt">bins =</span> <span class="dv">12</span>, <span class="dt">position =</span> <span class="st">&quot;identity&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.7</span>)</code></pre></div>
<p><img src="sirius_advanced_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<ol start="6" style="list-style-type: decimal">
<li>Теперь исследуем взаимосвязь переменных. Посчитайте коэффициент корреляции Пирсона и Спирмена.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[, <span class="kw">cor.test</span>(BodyWeightKG, BackpackWeightKG)]</code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  BodyWeightKG and BackpackWeightKG
## t = 1.9088, df = 98, p-value = 0.05921
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.007360697  0.371918344
## sample estimates:
##       cor 
## 0.1893312</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[, <span class="kw">cor.test</span>(BodyWeightKG, BackpackWeightKG, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>)]</code></pre></div>
<pre><code>## Warning in cor.test.default(BodyWeightKG, BackpackWeightKG, method =
## &quot;spearman&quot;): Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  BodyWeightKG and BackpackWeightKG
## S = 131520, p-value = 0.03527
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.2108001</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Постройте диаграмму рассеяния с помощью ggplot2. Цветом закодируйте пол респондента.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(back, <span class="kw">aes</span>(<span class="dt">x =</span> BodyWeightKG, <span class="dt">y =</span> BackpackWeightKG))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> Sex), <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">size =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="sirius_advanced_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
<div id="lm" class="section level2">
<h2><span class="header-section-number">2.2</span> Простая линейная регрессия</h2>
<p>Вы уже умеете считать коэффициент корреляции Пирсона:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[,<span class="kw">cor.test</span>(BackpackWeightKG, BodyWeightKG)]</code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  BackpackWeightKG and BodyWeightKG
## t = 1.9088, df = 98, p-value = 0.05921
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.007360697  0.371918344
## sample estimates:
##       cor 
## 0.1893312</code></pre>
<p>Простая линейная регрессия - это примерно то же самое. В синтаксисе линейной регрессии уже не обойтись без формул, это такой специальный тип данных в R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(y <span class="op">~</span><span class="st"> </span>x)</code></pre></div>
<pre><code>## [1] &quot;formula&quot;</code></pre>
<p>Если видите эту волнистую линию - тильду, это, что значит перед Вами формула.</p>
<p>Давайте исследуем зависимость размера рюкзака от массы тела. В простой лингейной регрессии, в отличие от корреляции, есть направленность: одна переменная является как бы независимой переменной (предиктором), другая - как бы объясняемой переменной (outcome). В формуле предикторы находятся справа от тильды, а объясняемая переменная - слева.</p>
<p>Терминология линейной регрессии может немного запутать: если одна переменная предиктор, а другая объясняется этим предиктором, то кажется, что они должны быть обязательно связаны причинно-следственной связью. Это не так: обозначения условны, более того, Вы можете поменять переменные местами и ничего не изменится! Короче говоря, “линейная регрессия” не дает никакой магической каузальной силы переменным.</p>
<div id="lm" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Функция lm()</h3>
<p>Давайте посчитаем линейную регрессию функцией <code>lm()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(BackpackWeightKG <span class="op">~</span><span class="st"> </span>BodyWeightKG, <span class="dt">data =</span> back)
model</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BackpackWeightKG ~ BodyWeightKG, data = back)
## 
## Coefficients:
##  (Intercept)  BodyWeightKG  
##      2.71125       0.03713</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BackpackWeightKG ~ BodyWeightKG, data = back)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.4853 -1.7629 -0.4681  1.2893  9.8803 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   2.71125    1.37483   1.972   0.0514 .
## BodyWeightKG  0.03713    0.01945   1.909   0.0592 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.581 on 98 degrees of freedom
## Multiple R-squared:  0.03585,    Adjusted R-squared:  0.02601 
## F-statistic: 3.644 on 1 and 98 DF,  p-value: 0.05921</code></pre>
<p><code>print(model)</code> или просто <code>model</code> выводит коэфициенты линейной регрессии - это коэффициенты прямой, которая лучше всего подогнанна к данным. Как измеряется качество этой подгонки? В расстоянии точек исходных точек до прямой. По идее, расстояние до прямой нужно было бы считать просто по модулю. И так делают, хоть и очень редко. Обычно в линейной регрессии используются квадратичные расстояния точек до прямой для оценки расстояния (метод наименьших квадратов - ordinary least squares). Это дает кучу клевых математических свойств, например, возможность легко аналитически найти коэффициенты прямой линейной регрессии.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[, body <span class="op">:</span><span class="er">=</span><span class="st"> </span>BodyWeightKG]
back[, bp <span class="op">:</span><span class="er">=</span><span class="st"> </span>BackpackWeightKG]
<span class="kw">library</span>(ggplot2)
<span class="kw">ggplot</span>(<span class="dt">data =</span> back,<span class="kw">aes</span>(<span class="dt">x =</span> body, <span class="dt">y =</span> bp))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.3</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">slope =</span> <span class="fl">0.03713</span>, <span class="dt">intercept =</span> <span class="fl">2.71125</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">140</span>))</code></pre></div>
<p><img src="sirius_advanced_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Функция <code>predict()</code> позволяет скормить модели новые данные и получить предсказания для новых значений предикторов. Попробуем поиграть с этим немного. Допустим, предскажем вес рюкзака для студента весом в 100 кг:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(model, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">BodyWeightKG =</span> <span class="dv">100</span>))</code></pre></div>
<pre><code>##        1 
## 6.424229</code></pre>
<p>Мы можем даже попробовать какие-нибудь экстремальные значения для предикторов. Например, сколько будет весить рюкзак студента весом 1000 кг?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(model, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">BodyWeightKG =</span> <span class="dv">1000</span>))</code></pre></div>
<pre><code>##      1 
## 39.841</code></pre>
<p>Очевидно, что в этом не очень много смысла: студент весом 1000 кг не сможет ходить на занятия, поэтому и про вес рюкзака как-то не имеет смысл спрашивать. Это проблема экстрополяции: линейная регрессия позволяет более-менее достоверно предсказывать значения внутри диапазона значений, на которых была построена модель. Еще один “странный” пример - студент весом 0 кг.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(model, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">BodyWeightKG =</span> <span class="dv">0</span>))</code></pre></div>
<pre><code>##        1 
## 2.711255</code></pre>
<p>Здесь бессмысленность происходящего еще очевиднее. Конечно, вес студента не может быть равен нулю, иначе это не студент вовсе. Однако это позволяет понять, что такое intercept модели - это значение зависимой переменой в случае, если предиктор равен нулю. А коэффициент предиктора означает, насколько килограммов увеличивается вес рюкзака при увеличении веса студента на 1 кг: на 0.0371297. Не очень много!</p>
</div>
<div id="interpret" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Интерпретация вывода линейной регрессии</h3>
<p>Давайте еще раз посмотрим на <code>summary(model)</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BackpackWeightKG ~ BodyWeightKG, data = back)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.4853 -1.7629 -0.4681  1.2893  9.8803 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   2.71125    1.37483   1.972   0.0514 .
## BodyWeightKG  0.03713    0.01945   1.909   0.0592 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.581 on 98 degrees of freedom
## Multiple R-squared:  0.03585,    Adjusted R-squared:  0.02601 
## F-statistic: 3.644 on 1 and 98 DF,  p-value: 0.05921</code></pre>
<p>Теперь мы понимаем, что это за коэффициенты. Однако это всего лишь их оценка. Это значит, что мы допускаем, что в реальности есть некие настоящие коэффициенты линейной регрессии, а каждый раз собирая новые данные, они будут посчитаны как немного разные. Короче говоря, эти коэффициенты - те же статистики, со своим выборочным распределением и стандартными ошибками. На основе чего и высчитывается p-value для каждого коэффициента - вероятность получить такой и более отклоняющийся от нуля коэффициент при верности нулевой гипотезы - независимости зависимой переменной от предиктора.</p>
<p>Кроме p-value, у линейной регрессии есть R<sup>2</sup> - доля объясненной дисперсии. Как ее посчитать? Для начала давайте сохраним как отдельные колонки ошибки (необъясненную часть модели) и предсказанные значения (они означают объясненную часть модели). Можно убедиться, что сумма предсказанных значений и ошибок будет равна зависимой переменной.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model<span class="op">$</span>residuals</code></pre></div>
<pre><code>##           1           2           3           4           5           6 
## -0.73414413 -2.36666022 -0.19634292 -2.60017426 -2.11403371 -4.48531686 
##           7           8           9          10          11          12 
## -1.94561603 -4.01261202 -2.63272245 -3.82508188 -1.35615417  4.11950245 
##          13          14          15          16          17          18 
## -0.58483892 -0.58483892  0.62663298 -0.66904776  0.74339000 -1.75808589 
##          19          20          21          22          23          24 
## -0.28055176 -3.22218430  3.49749241  1.66855186 -0.16379474  0.64006870 
##          25          26          27          28          29          30 
## -2.72260803  2.75872534 -1.60878068 -2.80114012  5.42861891 -2.76859193 
##          31          32          33          34          35          36 
## -0.61738711  2.07161893 -0.90256180 -1.97816422  0.86014703  2.55775948 
##          37          38          39          40          41          42 
##  1.28119121 -0.41642125 -3.50735900 -1.49088831 -1.52457185  0.91180768 
##          43          44          45          46          47          48 
## -0.36476060  1.31373940 -0.53317827 -2.38009594 -2.14544654 -2.96955779 
##          49          50          51          52          53          54 
## -0.51974255 -0.70159594  3.04390004 -1.69298952  4.86054022  1.34628758 
##          55          56          57          58          59          60 
##  0.74339000  2.57460125 -0.36476060 -3.55901965 -0.98677064  1.08022535 
##          61          62          63          64          65          66 
## -1.12264013 -0.70159594 -0.75325660 -1.44036301 -0.97333492  9.88033377 
##          67          68          69          70          71          72 
##  0.59294945  1.11277354 -3.90929072 -2.54851361 -3.02121845  3.32907473 
##          73          74          75          76          77          78 
##  1.11277354  1.53381772 -1.77719836  6.20334021 -3.57245537 -1.18773650 
##          79          80          81          82          83          84 
##  1.90320125 -0.19634292  5.68124542  5.73290607 -2.38009594 -0.02792525 
##          85          86          87          88          89          90 
##  3.71757073  0.91180768 -0.78466943  1.36540005  3.49749241  1.59891409 
##          91          92          93          94          95          96 
##  2.92714302  2.75872534 -0.55115539  0.57497233  0.55585986  0.86014703 
##          97          98          99         100 
## -3.27384496  0.08883177 -0.98677064  1.22953056</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back<span class="op">$</span>residuals =<span class="st"> </span><span class="kw">residuals</span>(model)
back<span class="op">$</span>fitted =<span class="st"> </span><span class="kw">fitted</span>(model)

back[, bp <span class="op">-</span><span class="st"> </span>(fitted <span class="op">+</span><span class="st"> </span>residuals)]</code></pre></div>
<pre><code>##   [1]  0.000000e+00 -4.440892e-16  0.000000e+00 -4.440892e-16  4.440892e-16
##   [6] -4.440892e-16 -4.440892e-16  2.220446e-16  0.000000e+00  1.110223e-16
##  [11] -4.440892e-16  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
##  [16]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
##  [21]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
##  [26]  0.000000e+00  4.440892e-16  4.440892e-16  0.000000e+00  0.000000e+00
##  [31]  0.000000e+00  0.000000e+00  0.000000e+00 -4.440892e-16 -8.881784e-16
##  [36]  0.000000e+00  0.000000e+00  0.000000e+00 -2.220446e-16 -4.440892e-16
##  [41] -4.440892e-16  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
##  [46]  0.000000e+00  4.440892e-16  0.000000e+00  0.000000e+00  0.000000e+00
##  [51]  0.000000e+00 -4.440892e-16  0.000000e+00  0.000000e+00  0.000000e+00
##  [56]  0.000000e+00  0.000000e+00 -4.440892e-16  0.000000e+00  0.000000e+00
##  [61] -8.881784e-16  0.000000e+00  0.000000e+00 -4.440892e-16  0.000000e+00
##  [66]  0.000000e+00  0.000000e+00  0.000000e+00 -3.330669e-16  0.000000e+00
##  [71]  4.440892e-16  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
##  [76]  0.000000e+00 -3.330669e-16  4.440892e-16  0.000000e+00  0.000000e+00
##  [81]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
##  [86]  0.000000e+00  0.000000e+00 -8.881784e-16  0.000000e+00 -8.881784e-16
##  [91]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
##  [96] -8.881784e-16  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00</code></pre>
<p>Соответственно, вся сумма объясненной дисперсии разделяется на объясненую и необъясненную. Полная дисперсия (total sum of squares = TSS) может быть посчитана как сумма квадратов разниц со средним. Необъясненная дисперсия - это сумма квадратов ошибок - residual sum of squares (RSS).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rss &lt;-<span class="st"> </span>back[, <span class="kw">sum</span>(residuals<span class="op">^</span><span class="dv">2</span>)]
rss</code></pre></div>
<pre><code>## [1] 652.7272</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tss &lt;-<span class="st"> </span>back[, <span class="kw">sum</span>((bp <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(bp))<span class="op">^</span><span class="dv">2</span>)]
tss</code></pre></div>
<pre><code>## [1] 676.995</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span><span class="op">-</span><span class="st"> </span>rss<span class="op">/</span>tss</code></pre></div>
<pre><code>## [1] 0.03584628</code></pre>
<p>Это очень мало, мы объяснили всего 3.5846285% дисперсии. Собственно, и p-value больше, чем 0,05. При этом этот p-value тот же, что и при коэффициента корреляции Пирсона. А R<sup>2</sup> - это квадрат коэффициента корреляции Пирсона, если речь идет только об одном предикторе.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BackpackWeightKG ~ BodyWeightKG, data = back)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.4853 -1.7629 -0.4681  1.2893  9.8803 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   2.71125    1.37483   1.972   0.0514 .
## BodyWeightKG  0.03713    0.01945   1.909   0.0592 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.581 on 98 degrees of freedom
## Multiple R-squared:  0.03585,    Adjusted R-squared:  0.02601 
## F-statistic: 3.644 on 1 and 98 DF,  p-value: 0.05921</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(back<span class="op">$</span>bp, back<span class="op">$</span>body)<span class="op">$</span>estimate<span class="op">^</span><span class="dv">2</span></code></pre></div>
<pre><code>##        cor 
## 0.03584628</code></pre>
</div>
<div id="lm_a" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Допущения линейной регрессии</h3>
<p>Как и в случае с другими параметрическими методами, линейная регрессия имеет определенные допущения относительно используемых данных. Если они не соблюдаются, то все наши расчеты уровня значимости могут некорректными.</p>
<blockquote>
<p>Очень важно ставить вопрос о том, насколько результаты будут некорректными. Как сильно нарушения допущений будет влиять на модель? Ответ на этот вопрос может быть контринтуитивен. Например, достаточно большие отклонения от нормальности нам обычно не стражны при условии того, что выборка достаточно большая.</p>
</blockquote>
<p>Допущения линейной регрессии связаны с ошибками: они должны быть нормально распределены, а разброс ошибок должен не уменьшаться и не увеличиваться в зависимости от предсказанных значений. Это то, что называется гомоскедастичностью или гомогенностью (когда все хорошо) и гетероскедастичностью или гетерогенностью (когда все плохо).</p>
<p>Если мы применим функцию <code>plot()</code>, то получим 4 скаттерплота:</p>
<ol style="list-style-type: decimal">
<li><p><em>Зависимость ошибок от предсказанных значений.</em> На что здесь смотреть? На симметричность относительно нижней и верхней части графика, на то, что разброс примерно одинаковый слева и справа.</p></li>
<li><p><em>Q-Q plot.</em> Здесь все довольно просто: если ошибки являются выборкой из нормального распределения, то они выстраиваются в прямую линию. Если это мало похоже на прямую линию, то имеет место отклонение от нормальности.</p></li>
<li><p><em>Scale-Location plot.</em> Этот график очень похож на график 1, только по оси <em>у</em> используются квадратные корни модуля ошибки. Еще один способ исследовать гетеро(гомо)скедастичность и находить выбросы.</p></li>
<li><p><em>Residuals-Leverage plot.</em> Здесь по оси <em>х</em> - расстояние Кука, а по оси <em>у</em> - стандартизированный размер выбросов. Расстояние Кука показывает <em>high-leverage points</em> - точки, которые имеют экстремальные предсказанные значения, то есть очень большие или очень маленькие значения по предикторам. Для линейной регрессии такие значения имеют большее значение, чем экстремальные точки по предсказываемой переменной. Особенно сильное влияние имеют точки, которые имеют экстремальные значения и по предикторам, и по предсказываемой переменной. Одна такая точка может поменять направление регрессионной прямой! Расстояние Кука отражает уровень <em>leverage</em>, а стандартизированные ошибки отражают экстремальные значения по <em>у</em> (вернее, экстремальные отклонения от предсказанных значений). В этом графике нужно смотреть на точки с правой стороны графика, особенно если они находятся высоко или низко по оси <em>у</em>.</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(model)</code></pre></div>
<p><img src="sirius_advanced_files/figure-html/unnamed-chunk-23-1.png" width="672" /><img src="sirius_advanced_files/figure-html/unnamed-chunk-23-2.png" width="672" /><img src="sirius_advanced_files/figure-html/unnamed-chunk-23-3.png" width="672" /><img src="sirius_advanced_files/figure-html/unnamed-chunk-23-4.png" width="672" /></p>
<p>Давайте теперь нарисуем регрессионную прямую на скаттерплоте:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> back,<span class="kw">aes</span>(<span class="dt">x =</span> body, <span class="dt">y =</span> bp))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.3</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">slope =</span> model<span class="op">$</span>coefficients[<span class="dv">2</span>], <span class="dt">intercept =</span> model<span class="op">$</span>coefficients[<span class="dv">1</span>])</code></pre></div>
<p><img src="sirius_advanced_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p><strong>Самостоятельное задание:</strong></p>
<ol style="list-style-type: decimal">
<li><p>На практике порогом для экстремальных точек часто выбирают среднее ±2 или ±3 стандартных отклонения. Напишите функцию <code>is_outlier()</code>, которая возвращает <code>TRUE</code>, если значение выходит за 2 стандартных отклонения от среднего.</p></li>
<li><p>Затем измените функцию <code>is_outlier()</code> так, чтобы можно было бы самостоятельно вводить количество стандартных отклонений с помощью параметра <code>n =</code>. Пусть по умолчанию это будет 3. Но проверьте, что все работает и на 2!</p></li>
<li><p>Теперь измените функцию <code>is_outlier()</code> так, чтобы можно было выбирать функцию для меры центральности (<code>centr =</code>, по умолчанию - среднее) и функцию для меры разброса (<code>vary =</code>, по умолчанию - стандартное отклонение). Проверьте, что это работает на медиане и 3 <em>median absolute deviation</em>. Как Вы думаете, какой из вариантов подходит больше? Почему?</p></li>
</ol>
<blockquote>
<p>О, да, в R функция тоже может быть использована в качестве аргумента функции. Впрочем, это не первый случай, когда мы с этим сталкиваемся. Другой пример - функции семейства <code>*apply()</code>. Заметьте - там тоже в качестве аргумента выступала функция (как объект), а не просто название функции как строковая переменная. В этом задании нужно сделать так же.</p>
</blockquote>
</div>
<div id="outliers" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Влияние выбросов на линейную модель</h3>
<p>Давайте теперь попробуем посмотреть, как изменится модель, если выкинуть <em>high leverage points</em> (экстремальные значения по предиктору - body) и что будет, если выкинуть экстремальные значения по у. Обычная линия - регрессионная прямая для модели со всеми точками, штрихованная линия - регрессионная прямая для модели без экстремальных значений по предиктору, пунктирная линия - регрессионная прямая для модели без экстремальных значений по предсказываемой переменной.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">back[, body_outlier <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">is_outlier</span>(body)]
back[, bp_outlier <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">is_outlier</span>(bp)]
model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(BackpackWeightKG <span class="op">~</span><span class="st"> </span>BodyWeightKG, <span class="dt">data =</span> back[<span class="op">!</span><span class="kw">is_outlier</span>(body),])
<span class="kw">summary</span>(model1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BackpackWeightKG ~ BodyWeightKG, data = back[!is_outlier(body), 
##     ])
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.6526 -1.7471 -0.3773  1.1699  9.0854 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)   0.48577    1.65749   0.293  0.77011   
## BodyWeightKG  0.07128    0.02413   2.953  0.00397 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.548 on 94 degrees of freedom
## Multiple R-squared:  0.08491,    Adjusted R-squared:  0.07517 
## F-statistic: 8.722 on 1 and 94 DF,  p-value: 0.003971</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(BackpackWeightKG <span class="op">~</span><span class="st"> </span>BodyWeightKG, <span class="dt">data =</span> back[<span class="op">!</span><span class="kw">is_outlier</span>(bp),])
<span class="kw">summary</span>(model2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BackpackWeightKG ~ BodyWeightKG, data = back[!is_outlier(bp), 
##     ])
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.7843 -1.4343 -0.1363  1.4296  4.9122 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)   3.60560    1.13144   3.187  0.00196 **
## BodyWeightKG  0.01915    0.01610   1.190  0.23716   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.087 on 93 degrees of freedom
## Multiple R-squared:  0.01499,    Adjusted R-squared:  0.004402 
## F-statistic: 1.416 on 1 and 93 DF,  p-value: 0.2372</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> back, <span class="kw">aes</span>(<span class="dt">x =</span> body, <span class="dt">y =</span> bp, <span class="dt">colour =</span>bp_outlier, <span class="dt">shape =</span> body_outlier))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.3</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> model<span class="op">$</span>coefficients[<span class="dv">1</span>], <span class="dt">slope =</span> model<span class="op">$</span>coefficients[<span class="dv">2</span>])<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept=</span> model1<span class="op">$</span>coefficients[<span class="dv">1</span>], 
              <span class="dt">slope =</span> model1<span class="op">$</span>coefficients[<span class="dv">2</span>], <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept=</span> model2<span class="op">$</span>coefficients[<span class="dv">1</span>], 
              <span class="dt">slope =</span> model2<span class="op">$</span>coefficients[<span class="dv">2</span>], <span class="dt">linetype =</span> <span class="st">&quot;dotted&quot;</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">theme_minimal</span>()</code></pre></div>
<p><img src="sirius_advanced_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
</div>
</div>
<div id="lm_mult" class="section level2">
<h2><span class="header-section-number">2.3</span> Множественная линейная регрессия</h2>
<p>В множественной линейной регрессионной регрессии у нас появляется несколько предикторов. Какая модель лучше: где есть много предикторов или где мало предикторов? С одной стороны, чем больше предикторов, тем лучше: каждый новый предиктор может объяснить чуть больше необъясненной дисперсиии. С другой стороны, если эта прибавка маленькая (а она всегда будет не меньше нуля), то, возможно, новый предиктор просто объясняет “случайный шум”. В действительности, если у нас будет достаточно много предикторов, то мы сможем объяснить любые данные! Парадоксальным образом такая модель будет давать очень хорошие результаты на той выборке, по которой мы считаем коэффициенты, но делать очень плохие предсказания на новой выборке - это то, что в машинном обучении называют переобучением (<em>overfitting</em>). Идеальная модель будет включать минимум предикторов, которые лучше всего объясненяют исследуемую переменную. Это что-то вроде <a href="https://ru.wikipedia.org/wiki/Бритва_Оккама">бритвы Оккама</a> в статистике.</p>
<p>Поэтому часто используются показатели качества модели, которые “наказывают” модель за большое количество предикторов. Например, adjusted R<sup>2</sup>:</p>
<p><span class="math display">\[R_{adj} = 1 - (1 - R^2) \frac{n -1}{n - p - 1}\]</span></p>
<p>Здесь <em>n</em> - это количество наблюдений, <em>p</em> - количество параметров.</p>
<p>Итак, добавим новый предиктор - <em>Units</em>. Это количество кредитов, которые студенты взяли в четверти<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. Можно предположить, что чем больше у студента набрано кредитов, тем более тяжелый у нее/него рюкзак. Давайте добавим это как второй предиктор. Для этого нужно просто записать второй предиктор в формуле через плюс.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model3 &lt;-<span class="st"> </span><span class="kw">lm</span>(bp <span class="op">~</span><span class="st"> </span>body <span class="op">+</span><span class="st"> </span>Units, <span class="dt">data =</span> back)
<span class="kw">summary</span>(model3)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bp ~ body + Units, data = back)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.6221 -1.8347 -0.5023  1.2519 10.0623 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  0.28481    2.16170   0.132   0.8955  
## body         0.04391    0.01990   2.207   0.0297 *
## Units        0.13703    0.09456   1.449   0.1505  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.566 on 97 degrees of freedom
## Multiple R-squared:  0.05628,    Adjusted R-squared:  0.03682 
## F-statistic: 2.892 on 2 and 97 DF,  p-value: 0.06025</code></pre>
<p>Множественная линейная регрессия имеет еще одно допущение: отстутсвие мультиколлинеарности. Это значит, что предикторы не должны коррелировать друг с другом.</p>
<p>Для измерения мультколлинеарности существует <em>variance inflation factor</em> (<em>VIF-фактор</em>). Считается он просто: для предиктора <span class="math inline">\(i\)</span> считается линейная регрессия, где все остальные предикторы предсказывают предиктор <span class="math inline">\(i\)</span>.</p>
<p>Сам VIF-фактор считается на основе полученного R<sup>2</sup> регрессии:</p>
<p><span class="math display">\[VIF_i = \frac{1}{1 - R_i^2}\]</span></p>
<p>Если R<sub>i</sub><sup>2</sup> большой, то и VIF<sub>i</sub> выходит большим. Это означает, что предиктор сам по себе хорошо объясняется другими предикторами. Какой VIF считать большим? Здесь нет единого мнения, но если он выше 3 и особенно если он выше 10, то с этим нужно что-то делать.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">car<span class="op">::</span><span class="kw">vif</span>(model3)</code></pre></div>
<pre><code>##    body   Units 
## 1.05858 1.05858</code></pre>
<p>В нашем случае это не так. Но если бы VIF был большим для какого-либо предиктора, то можно было бы либо попробовать его выкинуть или же использовать анализ главных компонент (см. <a href="d4.html#pca">5.3</a>), о котором пойдет речь в один из следующих дней.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Потом, правда, оказалось, что в данном случае факторный анализ ничего не доказывает, зато метод оказался очень полезным и получил большое распространение (особенно в психологии).<a href="d1.html#fnref1">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="d2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
