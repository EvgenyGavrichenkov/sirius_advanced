
# Неделя 2, День 2 {#d2}

## Дисперсионный анализ (ANOVA) {#anova}

Дисперсионный анализ или ANOVA[^1] - один из самых распространенных методов статистического анализа в психологии и многих других дисциплинах. Дисперсионный анализ очень хорошо подходит для анализа данных, полученных в эксперименте - методе организации исследования, при котором исследователь напрямую управляет уровнями независимой переменной. Терминологическая связь между дисперсионным анализом и планированием эксперимента настолько тесная, что многие термины пересекаются, поэтому нужно быть осторожными. Как и в случае с линейной регрессией, если мы что-то называем "независимой переменной" (или "фактором"), это не порождает никакой каузальной связи.

[^1]: ANOVA от ANalysis Of VAriance, по-русски часто читается как "АНОВА".

> Еще одна важная вещь, которую нужно понимать про дисперсионный анализ, это то, что у этого метода очень запутывающее название: из названия кажется, что этот статистический метод для сравнения дисперсий. Нет, это не так (хотя такие статистические тесты тоже есть, и они нам сегодня пригодятся - см. \@ref(aova)). Нет, это просто сравнение средних в случае, если есть больше, чем 2 группы для сравнения.

У дисперсионного анализа очень много разновидностей, для которых придумали множество названий. "Обычная" ANOVA называется One-Way ANOVA, она же межгрупповая ANOVA, это аналог независимого т-теста для нескольких групп.

Давайте начнем сразу с проведения теста. Мы будем использовать  [данные с курса по статистике Университета Шеффилда про эффективность диет](https://www.sheffield.ac.uk/polopoly_fs/1.570199!/file/stcp-Rdataset-Diet.csv).

```{r}
library(data.table)
diet <- fread("data/stcp-Rdataset-Diet.csv")
```

Сделаем небольшой препроцессинг данных. Создадим дополнительные "факторные" переменные, создадим переменную, в которой будет разница массы "до" и "после", удалим `NA`.

```{r}
diet[, weight.loss := weight6weeks - pre.weight]
diet[, Dietf := factor(Diet, labels = LETTERS[1:3])]
diet[, Person := factor(Person)]
diet <- diet[complete.cases(diet),]
```

### Функция aov() {#aov}
 
Попробуем сразу провести дисперсионных анализ с помощью функции `aov()`:

```{r}
aov_model <- aov(weight.loss ~ Dietf, diet)
aov_model
summary(aov_model)
```

Мы получили что-то похожее на результат применения функции `lm()`. Правда, лаконичнее, но с новыми столбцами `Sum Sq`, `Mean Sq` и новой статистикой *F* вместо *t*. Что будет, если с теми же данными с той же формулой запустить `lm()` вместо `aov()`?

```{r}
summary(lm(weight.loss ~ Dietf, diet))
```

`lm()` превратил `Dietf` в две переменные, но *F* и p-value у двух моделей одинаковые! Кроме того, функция `aov()` является, по сути, просто "оберткой" над `lm()`:

> This provides a wrapper to lm for fitting linear models to balanced or unbalanced experimental designs.

### Тестирование значимости нулевой гипотезы в ANOVA. {#anova_nhst}

Как и в случае с другими статистическими тестами, мы можем выделить 4 этапа в тестировании значимости нулевой гипотезы в ANOVA: 

1. __Формулирование нулевой и альтернативной гипотезы.__ Нулевая гипотеза говорит, что между средними в генеральной совокупности нет различий:

$$H_0:\mu_1 = \mu_2 = ... = \mu_n$$
Можно было бы предположить, что ненулевая гипотеза звучит как "все средние не равны", но вообще-то это не так. Альтернативная гипотеза в дисперсионном анализе звучит так:

$$H_1: \text{Не все средние равны}$$

2. __Подсчет статистики.__ Как мы уже видели раньше, в дисперсионном анализе используется новая для нас статистика *F*. Впрочем, мы ее видели, когда смотрели на аутпут функции `lm()`, когда делали линейную регрессию.
Чтобы считать *F* (если вдруг мы хотим сделать это вручную), нужно построить талбицу ANOVA (ANOVA table).  

-------------------------------------------------------------------------------------------------------------------------------------------------------------------
Таблица ANOVA                 Степени свободы    Суммы квадратов            Средние квадраты                                    F-статистика           
---------------------------- ----------------- --------------------------- ----------------------------------------- ----------------------------------
Межгрупповые                  $df_{b}$           $SS_{b}$                  $MS_{b} =\frac{SS_{b}}{df_{b}}$              $F=\frac{MS_{b}}{MS_{w}}$

Внутригрупповые               $df_{w}$           $SS_{w}$                  $MS_{w} =\frac{SS_{w}}{df_{w}}$  

Общие                         $df_{t}$          $SS_{t}= SS_{b} + SS_{w}$             
-------------------------------------------------------------------------------------------------------------------------------------------------------------------

Именно эту таблицу мы видели, когда использовали функцию `aov()`:

```{r}
summary(aov_model)
```

Вот как это все считается:



----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Таблица ANOVA           Степени свободы                                         Суммы квадратов                                                Средние квадраты                                    F-статистика           
--------------------- ---------------------- ---------------------------------------------------------------------------------------- ----------------------------------------------- -----------------------------------------------------------------------------------------
Между                 $df_{b}=J-1$            $SS_{b}= \sum\limits_{j=1}^J \sum\limits_{i=1}^{n_j} (\overline{x_j}-\overline{x})^2$        $MS_{b} =\frac{SS_{b}}{df_{b}}$                     $F=\frac{MS_{b}}{MS_{w}}$

Внутри                $df_{w}=N-J$            $SS_{w}= \sum\limits_{j=1}^J \sum\limits_{i=1}^{n_j} (x_{ij}-\overline{x_j})^2$              $MS_{w} =\frac{SS_{w}}{df_{w}}$  

Общие                 $df_{t}=N-1$            $SS_{t}= \sum\limits_{j=1}^J \sum\limits_{i=1}^{n_j} (x_{ij}-\overline{x})^2$             
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

$J$ означает количество групп, $N$ - общее количество наблюдений во всех группах, $n_j$ означает количество наблюдений в группе j, а $x_{ij}$ - наблюдение под номером $i$ в группе $j$. 

Вариабельность обозначается $SS$ и означает "сумму квадратов" (sum of squares) - это то же, что и дисперсия, только мы не делим вме в конце на количество наблюдений (или количество наблюдений минус один): $$SS = \sum\limits_{i=1}^{n_j} (x_{i}-\overline{x})^2$$ 

Здесь много формул, но суть довольно простая: мы разделяем вариабельность зависимой переменной на внутригрупповую и межгрупповую, считаем их соотношение, которое и будет *F*. В среднем, *F* будет равен 1 при верности нулевой гипотезы. Это означает, что и межгрупповая вариабельность, и внутригрупповая вариабельность - это просто шум. Но если же межгрупповая вариабельность - это не просто шум, то это соотношение будет сильно больше единицы.

3. __Подсчет p-value.__ В т-тесте мы смотрели, как статистика распределена при условии верности нулевой гипотезы. То есть что будет, если нулевая гипотеза верна, мы будем повторять эксперимент с точно таким же дизайном (и размером выборок) бесконечное количество раз и считать *F*. 


```{r, fig.cap="\\label{fig:fig1}F-распределение при верности нулевой гипотезы (см. детали в тексте)", out.width = '60%'}

betweendf <- 2
withindf <- 73
f <- summary(aov_model)[[1]]$F[1]

v <- seq(0.1,10, 0.01)
fdist <- data.frame(fvalues = v, pdf = df(v, betweendf, withindf))

library(ggplot2)

label <- paste0("F(", betweendf, ", ", withindf, ") = ", round(f, 3))

ggplot(fdist, aes(x = fvalues, y = pdf))+
  geom_line()+
  geom_vline(xintercept = f)+
  annotate("text", x = f+1, y = 0.2, label = label)+
  scale_y_continuous(expand=c(0,0)) + 
  theme_minimal()+
theme(axis.line.y = element_blank(),
      axis.ticks.y = element_blank(),
      axis.text.y = element_blank(),
      axis.title.y = element_blank())  
```

Заметьте, распределение *F* несимметричное[^2]. Это значит, что мы всегда считаем считаем площадь от *F* до плюс бесконечности (без умножения на 2, как мы это делали в т-тесте):

```{r}
1 - pf(f, betweendf, withindf)
```


[^2]: Форма *F*-распределения будет сильно зависеть от числа степеней свободы. Но оно всегда определено от 0 до плюс бесконечности: в числителе и знаменателе всегда неотрицательные числа.

Это и есть наш p-value! 

4.  __Сравнение p-value с уровнем $\alpha$.__ Самый простой этап: если наш p-value меньше, чем $\alpha$ (который обычно равен .05), то мы отвергаем нулевую гипотезу. Если нет - не отвергаем.  

В нашем случае это `r 1 - pf(f, betweendf, withindf)`, что, очевидно, меньше, чем .05. Отвергаем нулевую гипотезу (о том, что нет различий), принимаем ненулевую (о том, что различия есть). Все!

### Post-hoc тесты {#anova_posthoc}

Тем не менее, дисперсионного анализа недостаточно, чтобы решить, какие именно группы между собой различаются. Для этого нужно проводить post-hoc тесты (апостериорные тесты).

Post-hoc переводится с латыни как "после этого". Post-hoc тесты проводятся, если в результате ANOVA Вы отвергли нулевую гипотезу. Собственно, пост-хоки никак не связаны с дисперсионным анализом на уровне расчетов - это абсолютно независимые тесты, но исторически так сложилось, что они известны именно как дополнительный этап ANOVA.

Самый простой вариант пост-хок теста - это попарные т-тесты с поправками на множественные сравнения:

```{r}
pairwise.t.test(diet$weight.loss, diet$Dietf)
```

Второй подход связан с использованием специализированных тестов, таких как тест Тьюки (Tukey Honest Significant Differences = Tukey HSD). Для этого в R есть функция `TukeyHSD()`, которую нужно применять на объект `aov`:

```{r}
TukeyHSD(aov_model)
```

### ANOVA и т-тест как частные случаи линейной регрессии {#aov_as_lm}

Как мы уже видели, если применить `lm()` или `aov()` на одних и тех же данных с одной и той же формулой, то результат будет очень похожим. Но есть одно но: `lm()` создает из одного фактора две переменных-предиктора:

```{r}
summary(lm(weight.loss ~ Dietf, diet))
```

Дело в том, что мы не можем просто так загнать номинативную переменную в качестве предиктора в линейную регрессию. Мы можем это легко сделать, если у нас всего два уровня в номинативном предикторе. Тогда один из уровней можно обозначить за 0, другой - за 1. Такие переменные иногда называются "бинарными". Тогда это легко использовать в линейной регрессии:

```{r}
summary(lm(weight.loss ~ gender, diet))
```

Можно ли так делать? Вполне! Допущения линейной регрессии касаются остатков, а не переменных самих по себе. Разве что это немного избыточно: линейная регрессия с бинарным предиктором - это фактически независимый т-тест:

```{r}
t.test(weight.loss ~ gender, diet, var.equal = TRUE)
```

Как видите, p-value совпадают! А *t* статистика в квадрате - это *F* (при двух группах):

```{r}
t.test(weight.loss ~ gender, diet, var.equal = TRUE)$statistic^2
```

Более того, те же самые результаты можно получить и с помощью коэффициента корреляции Пирсона:

```{r}
cor.test(diet$gender, diet$weight.loss)
```

Теперь должно быть понятно, почему все эти функции делают вроде бы разные статистические тесты, но выдают такой похожий результат - это фактически один и тот же метод! Все эти методы (и некоторые из тех, что будем рассматривать далее) можно рассматривать как разновидности множественной 
линейной регрессии. [^3]

[^3]: Обобщением множественной линейной регрессии (вернее, одним из) можно считать общую линейную модель (general linear model). Общая линейная модель может предсказывать не одну, а сразу несколько объясняемых переменных в отличие от множественной линейной регрессии. Следующим этапом обобщения служит обобщенная линейная модель (generalized linear model). Фишка последней в том, что можно использовать не только модели с нормально распределенными остатками, но и, например, логистическую и пуассоновскую регрессию.

### Dummy coding {#dummy}

Тем не менее, вопрос остается открытым: как превратить номинативную переменную в количественную и загнать ее в регрессию? Для этого можно использовать "фиктивное кодирование" (dummy coding):

```{r}
diet[, isA := as.numeric(Dietf == "A")]
diet[, isB := as.numeric(Dietf == "B")]
diet[, isC := as.numeric(Dietf == "C")]
diet[c(1:2,15:16,35:36),c("Dietf", "isA", "isB", "isC")]
```

Заметьте, что такое кодирование избыточно. Если мы знаем, что диет 3, а данная диета - это не диета В и не диета С, то это диета А. Значит, одна из созданных нами колонок - "лишняя":

```{r}
diet[, isA := NULL]
```

Используем новую колонки для линейной регрессии и сравним результаты:

```{r}
summary(lm(weight.loss ~ isB + isC, diet))
summary(lm(weight.loss ~ Dietf, diet))
```

То же самое!

### Допущения ANOVA {#aova}

1. __Нормальность распределения ошибок:__

```{r}
hist(residuals(aov_model))
```

Как мы видим, распределение не сильно далеко от нормального - этого вполне достаточно. ANOVA - это метод достаточно устойчивый к отклонениям от нормальности.

2. __Гомогенность дисперсий.__ 

То есть их равенство. Можно посмотреть на распределение остатков:

```{r}
diet$residuals <- residuals(aov_model)
ggplot(diet, aes(x = Dietf, y = residuals))+ geom_jitter(width = 0.1, alpha = 0.5)
```

Все выглядит неплохо: нет какой-то одной группы, у которой разброс сильно больше или меньше. Есть и более формальные способы проверить равенство дисперсий. Например, с помощью теста Ливиня (Levene's test). Для того, чтобы его провести, мы воспользуемся новым пакетом `ez` (читать как "easy"). Этот пакет сильно упрощает проведение дисперсионного анализа, особенно для более сложных дизайнов.


```{r, eval = FALSE}
install.packages("ez")
```

Синтаксис довольно простой: нужно указать, данные, зависимую переменную, переменную с ID, факторы. Необходимо прописать фактор в `between =` или `within =`. В данном случае - в `between =`.

```{r}
library(ez)
ez_model <- ezANOVA(data = diet,
        dv= weight.loss,
        wid = Person, 
        between = Dietf,
        detailed = T, 
        return_aov = T)
ez_model
```

Если при проведении теста Ливиня мы получаем *p < .05*, то мы отбрасываем нулевую гипотезу о равенстве дисперсий. В данном случае мы не можем ее отбросить и поэтому принимаем [^4]

[^4]: Вообще-то эта логика не совсем корректна. Тест Ливиня - это такой же статистический тест, как и остальные. Поэтому считать, что допущения соблюдаются на основании того, что p-value больше допустимого уровня $\alpha$, - это неправильно. Но для проверки допущений такая не очень корректная практика считается допустимой.


Полученный объект (если поставить `return_aov = T`) содержит еще и объект `aov()` - на случай, если у Вас есть функции, которые работают с этим классом:

```{r}
TukeyHSD(ez_model$aov)
```

3. __Примерно одинаковое количество испытуемых в разных группах.__ Здесь у нас все в порядке: 

```{r}
diet[,.N, by = Dietf]
```

Небольшие различия в размерах групп - это ОК, тем более, что на практике такое очень часто случается: кого-то пришлось выкинуть из анализа, для какой-то строчки были потеряны данные и т.д. Однако больших различий в размерах групп стоит избегать. Самое плохое, когда группы различаются значительно по размеру (более чем в 2 раза) и вариабельность внутри групп отличается значительно (более чем в 2 раза).

### Многофакторный дисперсионный анализ (Factorial ANOVA) {#fact_aov}

На практике можно встретить One-Way ANOVA (однофакторную ANOVA) довольно редко. Обычно в исследованиях встречается многофакторный дисперсионный анализ, в котором проверяется влияние сразу нескольких факторов. В научных статьях это обозначается примерно так: "3х2 ANOVA". Это означает, что был проведен двухфакторный дисперсионный анализ, причем в одном факторе было три уровня, во втором - два. В нашем случае это будут факторы "Диета" и "Пол". Это означает, что у нас две гипотезы: о влиянии диеты на потерю веса и о влиянии пола на потерю веса. Кроме того, появляется гипотеза о взаимодействии факторов - то есть о том, что разные диеты по разному влияют на потерю веса для разных полов.

Взаимодействие двух факторов хорошо видно на графике с линиями: если две линии параллельны, то взаимодействия нет. Если они не параллельны (пересекаются, сходятся, расходятся), то взаимодействие есть.

```{r}
diet[, genderf:=factor(gender, labels = c("ж", "м"))]
sem <- function(x) sd(x)/sqrt(length(x))
pivot <- diet[,.(meanloss = mean(weight.loss), se = sem(weight.loss)), by = .(Dietf, genderf)]

library(ggplot2)
pd = position_dodge(0.05)
ggplot(pivot, aes(x = Dietf, y = meanloss, colour = genderf))+
geom_line(aes(group = genderf), position = pd)+
geom_pointrange(aes(ymin = meanloss - se, ymax = meanloss +se), position = pd)
```


Как видно по картинке, разница в эффективности диеты С по сравнению с другими видна только для женщин. 

```{r}
ezANOVA(data = diet,
        dv= weight.loss,
        wid = Person, 
        between = .(Dietf, gender),
        detailed = T, 
        return_aov = T)
```

Итак, теперь мы проверяем три гипотезы вместо одной. Действительно, взаимодействие диеты и пола оказалось значимым, как и ожидалось.

### Дисперсионный анализ с повторными измерениями (Repeated-measures ANOVA) {#rm_aov}

Если обычный дисперсионный анализ - это аналог независимого т-теста для нескольких групп, то дисперсионный анализ с повторными измерениями - это аналог зависимого т-теста. В функции `ezANOVA()` для проведения дисперсионного анализа с повторными измерениями нужно просто поставить нужным параметром внутригрупповую переменную. Это означает, что в данном случае мы должны иметь данные в длинном формате, для чего мы воспользуемся функцией `melt()`:

```{r}
dietlong <- melt(diet,
measure = c("pre.weight", "weight6weeks"),
variable = "time",
value = "weight")
dietlongC <- droplevels(dietlong[Dietf == "C",])
```


```{r}
ezANOVA(dietlongC,
        dv = weight, 
        wid = Person,
        within = time)
```

### Смешанный дисперсионный анализ (Mixed between-within subjects ANOVA) {#mixed_aov}

Нам никто не мешает совмещать и внутригруппоые, и межгрупповые факторы вместе. 

```{r}
ezANOVA(dietlong,
        dv = weight, 
        wid = Person,
        within = time,
        between = Dietf)
```

Здесь нас интересует взаимодействие между факторами. Результаты, полученные для этой гипотезы, идентичны результатам по обычному дисперсионному анализу на разницу до и после - по сути это одно и то же.

### Заключение {#aov_sum}

Мы разобрали много разных вариантов дисперсионного анализа. И это неудивительно - дисперсионный анализ является одним из самых распространенных статистических методов, в особенности в экспериментальных науках.
При этом дисперсионный анализ можно представить как частный случай множественной линейной регрессии!


## RMarkdown {#rmd}

RMarkdown - это мощный инструмент создания отчетов с использованием R (и других языков программирования). С помощью RMarkdown можно превратить скрипт с анализом в красивый отчет - Word-документ, PDF-документ, веб-страницу, презентацию (с интерактивными элементами!). Кстати, этот сайт тоже сделан с помощью RMarkdown.

Вот как это работает:

[Как работает RMarkdown](https://d33wubrfki0l68.cloudfront.net/61d189fd9cdf955058415d3e1b28dd60e1bd7c9b/b739c/lesson-images/rmarkdownflow.png)

- В основе всего лежит [pandoc](https://pandoc.org) - программа, которая преобразует разные форматы друг в друга. Поскольку разные форматы и даже виды документов имеют много схожих элементов, это вохможно сделать: например, и Word-файлы, и LaTeX, и HTML-документы имеют заголовки разных уровней.

- [Markdown](https://daringfireball.net/projects/markdown/) - это еще одна разметка. Ее преимущество - в удобстве использовании и простоте синтаксиса. Например, именно эта разметка используется на [GitHub](https://github.com) для ReadMe файлов. Markdown-документы - это просто текстовые документы с .Md разрешением.

- [knitr](https://yihui.org/knitr/) - R пакет для работы со специальными файлами .Rmd для превращения их в обычные .Md. Отличие .Rmd от .Md в наличии специально оформленных кусков кода (чанков). Эти куски кода выполняются и в .Md файле кроме самого кода (или даже без него) вставляется результат выполнения этого кода. Например, результат выполнения статистических тестов или график.

- [RMarkdown](https://rmarkdown.rstudio.com/index.html) - просто удобная оболочка над [knitr](https://yihui.org/knitr/) с нужными настройками.

Пример Markdown кода:

``` 
![Как работает RMarkdown](https://d33wubrfki0l68.cloudfront.net/61d189fd9cdf955058415d3e1b28dd60e1bd7c9b/b739c/lesson-images/rmarkdownflow.png)
```

![Как работает RMarkdown](https://d33wubrfki0l68.cloudfront.net/61d189fd9cdf955058415d3e1b28dd60e1bd7c9b/b739c/lesson-images/rmarkdownflow.png)


Вот так делать заголовки:

```
# R Markdown

## Что такое RMarkdown

## Чанки с кодом 
```

Это чанк с кодом. Он отделяется ``` с обоих сторон и {r}. Это означает, что внутри находится код на R, который должен быть выполнен:


\`\`\` {r}  
2+2  
\`\`\`

```{r}
2+2
```


### Настройки чанка {#chunk}

У чанка с кодом есть набор настроек. Самый важные из них такие:

- _echo_: будет ли показан сам код

- _message_ и _warning_: будут ли показаны сообщения и предупреждения, всплывающие во время исполнения кода

- _eval_:  будет ли испольняться код внутри чанка

### Настройка нескольких чанков {#chunks}
 
Все эти настройки можно настроить как для отдельных чанков, так и для все чанков сразу:


```{r setup2}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


### Чанки с Python! {#python}

Вместо {r} нужно написать {python}

```{python}
x = 'hello, python !'
print (x.split(" "))
```

### Код вне чанков (inline code) {#inline}

Число пи равно \` r pi \`:

```Число пи равно `r pi` ```

### Синтаксис Markdown (без R) {#md}

#### Выделение текста {#md_high}

```
*Курсив* 
_Тоже курсив_
**Полужирный**
__Тоже полужирный__
```

*Курсив* 
_Тоже курсив_
**Полужирный**
__Тоже полужирный__

#### Заголовки разных уровней {#headers}

```
## Заголовки разных уровней

### Мне заголовок

#### И моему сыну тоже

##### И моему!

###### OK, boomer

```

#### Списки {#md_lists}

* Первый вариант списка выглядит так:  

  + Можно и с подсписком
  + Почему бы и нет?

1. Кому нужен порядок
2. Тот списки номерует

#### Цитаты {#md_cite}

Цитата:

> Я устал  
> Который год во мне живет нарвал

### Таблицы {#rmd_tables}

```{r data, message=FALSE, warning = FALSE}
library(data.table)
go <- fread("data/iGLAS for R course.csv")
go[1:4,1:4]
```


```{r}
library(knitr)
kable(go[1:5,1:4])
```

#### Динамические таблицы {#dynamic_tables}

```{r}
library(DT)
datatable(go[1:5, 1:5])
```

### Визуализации {#vis}

```{r}
library(ggplot2)
library(Stat2Data)
library(data.table)
data("Backpack")
back <- as.data.table(Backpack)

ggplot_scatter <- ggplot(back, aes(x = BodyWeight, y = BackpackWeight))+
  geom_point(aes(colour = Sex), alpha = 0.5, size = 2)
ggplot_scatter
```

### Динамические визуализации в plotly {#din_vis}

```{r}
library(plotly)
ggplotly(ggplot_scatter)
```


### Вставлять HTML {#html}

Можно собирать RMarkdown документ в разные форматы: .pdf (с помощью LaTeX), Word-файл, HTML-страницу и некоторые другие форматы. Если во собираете документ соответствующего формата, то вам доступны и соответствующие плюшки этого формата. Например, этот сайт - это .Rmd, собранный в HTML. Я могу вставлять сюда любой HTML код. Например, видео с YouTube!

```
<iframe width="966" height="543" src="https://www.youtube.com/embed/hHW1oY26kxQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
```

<iframe width="966" height="543" src="https://www.youtube.com/embed/hHW1oY26kxQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

